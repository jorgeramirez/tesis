\section{2000 - Actualidad}
\label{sec:post2000s}

% 47, 76, 25, 23, 38, 36, 90

En los inicios del segundo milenio, el \'{a}rea de reconocimiento del habla ya hab\'{i}a avanzado 
considerablemente. Resultados prometedores fueron obtenidos en el reconocimiento de palabras aisladas
dependientes del interlocutor, y los esfuerzos de los investigadores se centraban en el habla espont\'{a}nea,
independencia del interlocutor y robustez en condiciones ruidosas \cite{RonzhinSurvey2006}.

El programa EARS de DARPA se llev\'{o} a cabo para desarrollar tecnolog\'{i}as para la transcripci\'{o}n 
autom\'{a}tica con el objetivo de conseguir mejores resultados. 
Las tareas incluyen detecci\'{o}n de l\'{i}mites de oraciones, palabras de relleno 
y fonemas o palabras repetidas conocidos como disfluencias. 
La meta era permitir que las computadoras puedan tener un mejor desempe\~{n}o en la detecci\'{o}n, extracci\'{o}n, 
s\'{i}ntesis y traducci\'{o}n de informaci\'{o}n importante \cite{LiuStructural2005, SoltauTheIBM2005}.

Como se mencion\'{o} anteriormente, los investigadores se enfocaban en el reconocimiento del habla espont\'{a}nea, 
ya que el nivel de precisi\'{o}n disminu\'{i}a bastante bajo esta situaci\'{o}n. Varios programas de 
investigaci\'{o}n se llevaron a cabo para incrementar el nivel de precisi\'{o}n. En el 2005 finaliz\'{o} un 
programa de 5 a\~{n}os que se llev\'{o} a cabo en Jap\'{o}n, los resultados obtenidos incluyen un 
Corpus de Japon\'{e}s Espont\'{a}neo (o CSJ por sus siglas del ingl\'{e}s) y nuevas t\'{e}cnicas como: 
modelado ac\'{u}stico flexible, detecci\'{o}n de l'{i}mites de una oraci\'on, modelado de pronunciaci\'{o}n,
adaptaciones al modelo ac\'{u}stico y de lenguaje, y
resumen autom\'{a}tico \cite{FuruiRecent2005}.

Con el objetivo de mejorar la robustez de los resultados prove\'{i}dos por los sistemas de reconocimiento del habla, 
especialmente en el habla espont\'{a}nea, importantes esfuerzos se enfocaron en desarrollar t\'{e}cnicas para medir 
la confiabilidad de lossistemas. Estas tareas de investigaci\'{o}n se agrupan bajo el nombre de 
Reconocimiento Robusto del Habla. Esta \'{a}rea propuso la utilizaci'{o}n de Medidas de Confianza (CM) para indicar 
la confiabilidad de los resultados de un sistema de reconocimiento \cite{JiangConfidence2005}.

A partir de la segunda mitad de los 2000 el reconocimiento del habla lleg\'{o} a los dispositivos m\'{o}viles. 
En el 2008 fue lanzado Google Voice Search para iPhone permitiendo que usuarios puedan hacer consultas al 
buscador de Google con la voz, actualmente el software forma parte del la aplicaci\'{o}n Google Search y 
se encuentra disponible para Android y otras plataformas \cite{GoogleSearch}. 
Siri\footnote{Siri fue inicialmente desarrollada por Siri Inc. en el 2007, la empresa fue posteriormente 
adquirida por Apple Inc. en el 2010.}es una aplicaci\'{o}n de asistente personal inteligente lanzada como parte
integral de iOS\footnote{iOS es un sistema operativo m\'{o}vil desarrollado por Apple Inc.}desde el 2011, 
la aplicaci\'{o}n utiliza procesamiento del lenguaje natural para responder preguntas, hacer recomendaciones y
realizar acciones a trav\'{e}s de servicios web \cite{AppleSiri}.

En lo que respecta a aplicaciones web, en el 2012 Google introdujo la \foreign{Web Speech API} que es una interfaz de 
programaci\'{o}n de aplicaciones que permite a los desarrolladores incorporar 
reconocimiento y s\'{i}ntesis del habla a sus aplicaciones o sitios web \cite{GoogleWebSpeechAPI}.
