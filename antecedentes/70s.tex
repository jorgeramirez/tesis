%!TEX root = ../tesis.tex
\section{1970 - 1980}
\label{sec:70s}

El cambio de paradigma más importante para el progreso del reconocimiento del habla ha sido, sin duda alguna,
la introducción de métodos estadísticos, especialmente el procesamiento estocástico con modelos ocultos de
Markov (HMM por sus siglas en inglés). Aún después de 30 años, esta metodología aún predomina en los
sistemas \mbox{actuales \cite{BakerResearch2009}}.

La teoría básica de los modelos ocultos de Markov fue publicada en una serie de papers, hoy en día clásicos,
de Baum y sus colegas a finales de los años 60 e inicios de los años 70. Esta fue implementada por Baker en
el Carnegie Mellon University y por Jelinek y otros colegas en \mbox{IBM \cite{Rabiner89atutorial}}.

El programa de investigación sobre comprensión del lenguaje, abierto con fondos de la Agencia de Proyectos de Investigación Avanzada (ARPA por sus siglas en inglés) a inicios de la década de los 70 tuvo como 
resultado varios nuevos sistemas y \mbox{tecnologías \cite{Furui50Years2004}}.

Entre los sistemas construidos en el marco de este programa se destaca Harpy, de la Universidad de Carnegie Mellon,
capaz de reconocer el habla usando un vocabulario compuesto de 1011 palabras con precisión razonable. Harpy fue el
primer sistema en un utilizar una red de estados finitos para reducir el cómputo y determinar eficientemente la
cadena de salida. Sin embargo, los métodos para optimizar las redes de estado finito no surgieron hasta inicios de
la década de los \mbox{90 \cite{JuangAutomaticSpeech}}.

Otros sistemas desarrollados bajo el mismo programa son Hersay(-II) también de CMU y HWIM de BBN. A pesar proponer
nuevos enfoques sumamente interesantes, ninguno de estos proyectos llegó a cumplir la meta en cuanto a rendimiento
del programa al momento de su conclusión, en \mbox{1976 \cite{JuangAutomaticSpeech}}.


